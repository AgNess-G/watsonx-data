{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Step 0\n\n## - Click \u22ee on the menu to the right \n## - \"Insert project token\" \n## Use the \u2b07 on the top menu to move the cell down and begin running the notebook", "id": "36b191f1"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": [], "id": "84e5d35a"}, {"metadata": {}, "id": "b65a7e72", "cell_type": "markdown", "source": "# Load Data into Milvus for RAG\n"}, {"metadata": {}, "id": "15258f81", "cell_type": "markdown", "source": " \n\n\n<a class=\"anchor\" id=\"setup\"></a>\n## 1. Set up the environment\n\n### Install Libraries\n\nWe need to install the pymilvus package to the watsonx.ai Python environment."}, {"metadata": {}, "id": "51677357", "cell_type": "code", "source": "!pip install grpcio==1.60.0 \n!pip install pymilvus", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "579e78ba", "cell_type": "markdown", "source": "## !!RESTART THE KERNAL AFTER pymilvus install!!\n\nCertain dependencies need to be persisted. Restarting the kernal allows this to occur. "}, {"metadata": {}, "id": "694eff33", "cell_type": "code", "source": "!pip install ipython-sql==0.4.1\n!pip install sqlalchemy==1.4.46\n!pip install sqlalchemy==1.4.46 \"pyhive[presto]\"\n!pip install python-dotenv\n!pip install wikipedia\n!pip install sentence_transformers", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "b747755a", "cell_type": "markdown", "source": "## Wikipedia Exploration"}, {"metadata": {}, "cell_type": "code", "source": "wikipedia_search_term = 'Climate Change'", "execution_count": null, "outputs": [], "id": "1a330037"}, {"metadata": {}, "id": "32f2b28a", "cell_type": "code", "source": "import wikipedia\n\n# search\nsearch_results = wikipedia.search(wikipedia_search_term)\nsearch_results\n\nprint(search_results)\n\n# view article summary\narticle_summary = wikipedia.summary(search_results[0])\narticle_summary\n\nprint(article_summary)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "d89314fa", "cell_type": "code", "source": "import wikipedia\n\n# fetch wikipedia articles\narticles = {\n    #'ADDITIONAL TITLES': None,\n    'Climate change': None\n}\n\nfor k,v in articles.items():\n    article = wikipedia.page(k)\n    articles[k] = article.content\n    print(f\"Successfully fetched {k}\")\n\nprint(f\"Successfully fetched {len(articles)} articles \")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "f5f350d8", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "4353d5b0", "cell_type": "markdown", "source": "### Split Wikipedia Data into Chunks"}, {"metadata": {}, "id": "18894c13", "cell_type": "code", "source": "# Chunk data\ndef split_into_chunks(text, chunk_size):\n    words = text.split()\n    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n\nsplit_articles = {}\nfor k,v in articles.items():\n    split_articles[k] = split_into_chunks(v, 225)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "bb6dc64d", "cell_type": "code", "source": "article_titles = list(split_articles.keys())\narticle_chunks = list(split_articles.values())", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "947812bc", "cell_type": "code", "source": "## create titles_list for associates chunks to be loaded into milvus \n\ni = 0\nfor title in article_titles:\n    list_length = len(article_chunks[i])\n    article_titles[i] = [title] * list_length\n    i+=1\n    \n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a58926d6", "cell_type": "markdown", "source": "## Insert Chunks with Embeddings into Milvus"}, {"metadata": {}, "cell_type": "code", "source": "wslib.list_connections()", "execution_count": null, "outputs": [], "id": "c688932f"}, {"metadata": {}, "cell_type": "code", "source": "# note if you named your Milvus connection something other than 'Milvus Connection' please replace the name below \n\nmilvus_credentials = wslib.get_connection('Milvus Connection')", "execution_count": null, "outputs": [], "id": "de267d63"}, {"metadata": {}, "cell_type": "code", "source": "#milvus_credentials", "execution_count": null, "outputs": [], "id": "ff9ad5f7"}, {"metadata": {}, "id": "65714f49", "cell_type": "code", "source": "from pymilvus import(\n    Milvus,\n    IndexType,\n    Status,\n    connections,\n    FieldSchema,\n    DataType,\n    Collection,\n    CollectionSchema,\n)\n\n\nurl = milvus_credentials['host']\nport = milvus_credentials['port']\napikey = milvus_credentials['password']\napiuser = 'ibmlhapikey'\n\n\nconnections.connect(alias=\"default\", \n                    host=url, \n                    port=port, \n                    user=apiuser, \n                    password=apikey, \n                    secure=True)\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# feel free to change the description and title of the newly created collection \n\ncollection_description = 'collection description'\ncollection_name = 'wiki_articles'", "execution_count": null, "outputs": [], "id": "8ee146bc"}, {"metadata": {}, "id": "d4d98158", "cell_type": "code", "source": "# Create collection - define fields + schema\n\nfields = [\n    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Primary key\n    FieldSchema(name=\"article_text\", dtype=DataType.VARCHAR, max_length=2500,),\n    FieldSchema(name=\"article_title\", dtype=DataType.VARCHAR, max_length=200,),\n    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=384),\n]\n\nschema = CollectionSchema(fields, collection_description)\n\nwiki_collection = Collection(collection_name, schema)\n\n# Create index\nindex_params = {\n        'metric_type':'L2',\n        'index_type':\"IVF_FLAT\",\n        'params':{\"nlist\":2048}\n}\n\nwiki_collection.create_index(field_name=\"vector\", index_params=index_params)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "efbefcbe", "cell_type": "code", "source": "# we can run a check to see the collections in our milvus instance and we see the new collection has been created \n\nfrom pymilvus import utility\nutility.list_collections()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "7e2b9046", "cell_type": "code", "source": "# load data into Milvus\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nfrom pymilvus import Collection, connections\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfor i in range(len(article_titles)):\n    # Create vector embeddings + data\n    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n    passage_embeddings = model.encode(article_chunks[i])\n\n    basic_collection = Collection(collection_name) \n    data = [\n        article_chunks[i],\n        article_titles[i],\n        passage_embeddings\n    ]\n               \n    out = basic_collection.insert(data)\n    basic_collection.flush()  # Ensures data persistence\n\n    \n    print(\"Wikipedia Article: \\'\" + article_titles[i][0] + \"\\' has been loaded.\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "3547110e", "cell_type": "code", "source": "## check to ensure entities have been loaded into the collection\n\nbasic_collection = Collection(collection_name) \n\nbasic_collection.num_entities ", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "0f8253da", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "34a915ff", "cell_type": "markdown", "source": "### Prompt LLM with Query Results\n"}, {"metadata": {}, "id": "77e075a8", "cell_type": "code", "source": "from sentence_transformers import SentenceTransformer\nfrom pymilvus import(\n    Milvus,\n    IndexType,\n    Status,\n    connections,\n    FieldSchema,\n    DataType,\n    Collection,\n    CollectionSchema,\n)\n\nurl = milvus_credentials['host']\nport = milvus_credentials['port']\napikey = milvus_credentials['password']\napiuser = 'ibmlhapikey'\n\n\nconnections.connect(alias=\"default\", \n                    host=url, \n                    port=port, \n                    user=apiuser, \n                    password=apikey, \n                    secure=True)\n\n\n# Load collection\n\nbasic_collection = Collection(collection_name)      \nbasic_collection.load()\n\n# Query function\ndef query_milvus(query, num_results):\n    \n    # Vectorize query\n    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # 384 dim\n    query_embeddings = model.encode([query])\n\n    # Search\n    search_params = {\n        \"metric_type\": \"L2\", \n        \"params\": {\"nprobe\": 5}\n    }\n    results = basic_collection.search(\n        data=query_embeddings, \n        anns_field=\"vector\", \n        param=search_params,\n        limit=num_results,\n        expr=None, \n        output_fields=['article_text'],\n    )\n    return results", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "0f62a489", "cell_type": "code", "source": "## Consider some questions to ask regarding the topic you have chosen \n\n#question_text = \"OTHER QUESTION TEXT\"\n\nquestion_text = \"What is climate change?\"", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a8259b76", "cell_type": "code", "source": "# Query Milvus \n\nnum_results = 3\nresults = query_milvus(question_text, num_results)\n\nrelevant_chunks = []\nfor i in range(num_results):    \n    #print(f\"id: {results[0].ids[i]}\")\n    #print(f\"distance: {results[0].distances[i]}\")\n    text = results[0][i].entity.get('article_text')\n    relevant_chunks.append(text)\n    \n#print(relevant_chunks)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "c72ab9a3", "cell_type": "code", "source": "def make_prompt(context, question_text):\n    return (f\"{context}\\n\\nPlease answer a question using this text. \"\n          + f\"If the question is unanswerable, say \\\"unanswerable\\\".\"\n          + f\"\\n\\nQuestion: {question_text}\")\n\n\n# Build prompt w/ Milvus results\n# Embed retrieved passages(context) and user question into into prompt text\n\ncontext = \"\\n\\n\".join(relevant_chunks)\nprompt = make_prompt(context, question_text)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "aef20205", "cell_type": "code", "source": "print(prompt)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "47852e4f", "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n\n# Model Parameters\nparams = {\n        GenParams.DECODING_METHOD: \"greedy\",\n        GenParams.MIN_NEW_TOKENS: 1,\n        GenParams.MAX_NEW_TOKENS: 500,\n        GenParams.TEMPERATURE: 0,\n}\n\n\n# please note if using a cloud account in a different geography the cloud URL will be different \n# Refer to this list: \n#    Dallas - https://us-south.ml.cloud.ibm.com\n#    London - https://eu-gb.ml.cloud.ibm.com\n#    Frankfurt - https://eu-de.ml.cloud.ibm.com\n#    Tokyo - https://jp-tok.ml.cloud.ibm.com\n\ncreds = {\n    \"url\": 'https://us-south.ml.cloud.ibm.com',\n    \"apikey\": milvus_credentials['password'] \n}\n\nmodel = Model(\n        model_id='ibm/granite-13b-chat-v2', \n        #model_id='meta-llama/llama-2-70b-chat', \n        params=params, credentials=creds, \n        project_id=wslib.here.get_ID()\n)\n\n# Prompt LLM\nresponse = model.generate_text(prompt)\nprint(f\"Question: {question_text}{response}\")", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "f9503c73", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "5faa6b69", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "8dedcfc9", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "vscode": {"interpreter": {"hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}}, "nbformat": 4, "nbformat_minor": 5}